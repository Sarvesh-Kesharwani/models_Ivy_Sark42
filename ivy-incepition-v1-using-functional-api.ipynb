{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T08:45:17.243895Z","iopub.status.busy":"2023-08-06T08:45:17.243067Z","iopub.status.idle":"2023-08-06T08:45:18.440977Z","shell.execute_reply":"2023-08-06T08:45:18.439567Z","shell.execute_reply.started":"2023-08-06T08:45:17.243853Z"},"trusted":true},"outputs":[],"source":["# ! rm -r /kaggle/working/"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-06T12:32:20.296234Z","iopub.status.busy":"2023-08-06T12:32:20.295877Z","iopub.status.idle":"2023-08-06T12:32:42.372357Z","shell.execute_reply":"2023-08-06T12:32:42.371067Z","shell.execute_reply.started":"2023-08-06T12:32:20.296208Z"},"papermill":{"duration":42.609401,"end_time":"2023-07-30T17:11:01.147922","exception":false,"start_time":"2023-07-30T17:10:18.538521","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["!pip install -q ivy\n","\n","# !git clone https://github.com/unifyai/models.git\n","# !cd models && python3 -m pip install -q -e .\n","!python3 -m pip install torchvision"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:32:42.374948Z","iopub.status.busy":"2023-08-06T12:32:42.374626Z","iopub.status.idle":"2023-08-06T12:32:42.960957Z","shell.execute_reply":"2023-08-06T12:32:42.959465Z","shell.execute_reply.started":"2023-08-06T12:32:42.374914Z"},"trusted":true},"outputs":[],"source":["import ivy\n","import numpy as np\n","import torch\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:37:23.656663Z","iopub.status.busy":"2023-08-06T12:37:23.656264Z","iopub.status.idle":"2023-08-06T12:37:23.664894Z","shell.execute_reply":"2023-08-06T12:37:23.663162Z","shell.execute_reply.started":"2023-08-06T12:37:23.656632Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["class ConvBlock(ivy.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        super(ConvBlock, self).__init__()\n","\n","    def _build(self, *args, **kwargs):\n","        self.conv = ivy.Conv2D(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding, with_bias=False, data_format=\"NCHW\")\n","        self.bn = ivy.BatchNorm2D(self.out_channels, eps=0.001, data_format=\"NCS\")\n","\n","    def _forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = ivy.relu(x)\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:37:25.209456Z","iopub.status.busy":"2023-08-06T12:37:25.208720Z","iopub.status.idle":"2023-08-06T12:37:28.027292Z","shell.execute_reply":"2023-08-06T12:37:28.025828Z","shell.execute_reply.started":"2023-08-06T12:37:25.209421Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'random_test_tensor shape is: ivy.Shape(1, 3, 224, 224)'"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n"]},{"data":{"text/plain":["'calc_output_shape is: ivy.Shape(1, 64, 112, 112) | and true_output_shape is: (1, 64, 112, 112)'"]},"metadata":{},"output_type":"display_data"}],"source":["def test_conv_block():\n","    # testing with 1st ConvBlock configs in the googlenet block\n","    # ie, self.conv1 = ConvBlock(3, 64, [7,7], 2, padding=3)\n","    # random_test_tensor = ivy.random_normal(shape=(1, 224, 224, 3))\n","    random_test_tensor = ivy.random_normal(shape=(1, 3, 224, 224))\n","\n","    display(f\"random_test_tensor shape is: {random_test_tensor.shape}\")\n","    \n","    conv_block = ConvBlock(3, 64, [7,7], 2, padding=3)\n","    calc_output_shape = conv_block(random_test_tensor).shape\n","    # true_output_shape = (1, 112, 112, 64)\n","    true_output_shape = (1, 64, 112, 112)\n","\n","    display(f\"calc_output_shape is: {calc_output_shape} | and true_output_shape is: {true_output_shape}\")\n","    \n","    assert calc_output_shape == true_output_shape;\n","\n","test_conv_block()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:37:37.234527Z","iopub.status.busy":"2023-08-06T12:37:37.234137Z","iopub.status.idle":"2023-08-06T12:37:37.247591Z","shell.execute_reply":"2023-08-06T12:37:37.246298Z","shell.execute_reply.started":"2023-08-06T12:37:37.234495Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["class Inception(ivy.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        num1x1,\n","        num3x3_reduce,\n","        num3x3,\n","        num5x5_reduce,\n","        num5x5,\n","        pool_proj,\n","    ):\n","        self.in_channels = in_channels\n","        self.num1x1 = num1x1\n","        self.num3x3_reduce = num3x3_reduce\n","        self.num3x3 = num3x3\n","        self.num5x5_reduce = num5x5_reduce\n","        self.num5x5 = num5x5\n","        self.pool_proj = pool_proj\n","        super(Inception, self).__init__()\n","\n","    def _build(self, *args, **kwargs):\n","        self.conv_1x1 = ConvBlock(self.in_channels, self.num1x1, kernel_size=[1, 1], stride=1, padding=0)\n","                                    \n","        self.conv_3x3 = ConvBlock(self.in_channels, self.num3x3_reduce, kernel_size=[1, 1], stride=1, padding=0)\n","        self.conv_3x3_red = ConvBlock(self.num3x3_reduce, self.num3x3, kernel_size=[3, 3], stride=1, padding=1)\n","                                   \n","        self.conv_5x5 = ConvBlock(self.in_channels, self.num5x5_reduce, kernel_size=[1, 1], stride=1, padding=0)\n","        self.conv_5x5_red = ConvBlock(self.num5x5_reduce, self.num5x5, kernel_size=[3, 3], stride=1, padding=1)\n","                                        \n","        self.pool_proj_conv = ConvBlock(self.in_channels, self.pool_proj, kernel_size=[1, 1], stride=1, padding=0)\n","                                        \n","    def _forward(self, x):\n","        # unit testing using ==> \"\"\"self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\"\"\"\n","        display('#######################################################################################')\n","        # 1x1\n","        display(f\"the input shape should be (1, 28, 28, 192) | and it is: {ivy.shape(x)}\")\n","        conv_1x1 = self.conv_1x1(x)\n","        \n","        # 3x3\n","        display(f\"the input shape should be () | and it is: {ivy.shape(x)}\")\n","        conv_3x3 = self.conv_3x3(x)\n","        \n","        display(f\"the input shape should be () | and it is: {ivy.shape(x)}\")\n","        conv_3x3_red = self.conv_3x3_red(conv_3x3)\n","        \n","        # 5x5\n","        display(f\"the input shape should be () | and it is: {ivy.shape(x)}\")\n","        conv_5x5 = self.conv_5x5(x)\n","        \n","        display(f\"the input shape should be () | and it is: {ivy.shape(x)}\")\n","        conv_5x5_red = self.conv_5x5_red(conv_5x5)\n","        \n","        # pool_proj\n","        display(f\"the input shape should be () | and it is: {ivy.shape(x)}\")\n","        pool_proj = ivy.max_pool2d(x, [3,3], 1, 1, ceil_mode=True, data_format=\"NCHW\")\n","        \n","        display(f\"the input shape should be () | and it is: {ivy.shape(x)}\")\n","        pool_proj = self.pool_proj_conv(pool_proj)\n","        \n","        display(f\"the input shape should be () | and it is: {ivy.shape(conv_1x1)}\")\n","        display(f\"the input shape should be () | and it is: {ivy.shape(conv_3x3_red)}\")\n","        display(f\"the input shape should be () | and it is: {ivy.shape(conv_5x5_red)}\")\n","        display(f\"the input shape should be (1, 1024) | and it is: {ivy.shape(pool_proj)}\")\n","        ret = ivy.concat([conv_1x1, conv_3x3_red, conv_5x5_red, pool_proj], axis=1)\n","        display(f\"the output shape should be (1, 28, 28, 256) | and it is: {ivy.shape(x)}\")\n","        display('#######################################################################################')\n","        \n","        return ret"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:37:39.226770Z","iopub.status.busy":"2023-08-06T12:37:39.226370Z","iopub.status.idle":"2023-08-06T12:37:53.480720Z","shell.execute_reply":"2023-08-06T12:37:53.479473Z","shell.execute_reply.started":"2023-08-06T12:37:39.226736Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'random_test_tensor shape is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n"]},{"data":{"text/plain":["'#######################################################################################'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be (1, 28, 28, 192) | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 64, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 128, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be () | and it is: ivy.Shape(1, 32, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape should be (1, 1024) | and it is: ivy.Shape(1, 32, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the output shape should be (1, 28, 28, 256) | and it is: ivy.Shape(1, 192, 28, 28)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'#######################################################################################'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'calc_output_shape is: ivy.Shape(1, 256, 28, 28) | and true_output_shape is: (1, 256, 28, 28)'"]},"metadata":{},"output_type":"display_data"}],"source":["def test_inception_block():\n","    # testing with 1st ConvBlock configs in the googlenet block\n","    # ie, self.inception3A = Inception(192, 64, 96, 128, 16, 32, 32)\n","    # random_test_tensor = ivy.random_normal(shape=(1, 28, 28, 192))\n","    random_test_tensor = ivy.random_normal(shape=(1, 192, 28, 28))\n","\n","    display(f\"random_test_tensor shape is: {random_test_tensor.shape}\")\n","    \n","    inception_block = Inception(192, 64, 96, 128, 16, 32, 32)\n","    calc_output_shape = inception_block(random_test_tensor).shape\n","    # true_output_shape = (1, 28, 28, 256)\n","    true_output_shape = (1, 256, 28, 28)\n","\n","    display(f\"calc_output_shape is: {calc_output_shape} | and true_output_shape is: {true_output_shape}\")\n","    \n","    assert calc_output_shape == true_output_shape;\n","\n","test_inception_block()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:37:53.484533Z","iopub.status.busy":"2023-08-06T12:37:53.484237Z","iopub.status.idle":"2023-08-06T12:37:53.496520Z","shell.execute_reply":"2023-08-06T12:37:53.495126Z","shell.execute_reply.started":"2023-08-06T12:37:53.484509Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["class Auxiliary(ivy.Module):\n","    def __init__(self, in_channels, num_classes):\n","        self.in_channels = in_channels\n","        self.num_classes = num_classes\n","        super(Auxiliary, self).__init__()\n","\n","    def _build(self, *args, **kwargs):\n","        self.conv = ConvBlock(self.in_channels, 128, [1,1], 1, 0)\n","        \n","        self.fc1 = ivy.Linear(2048, 1024)\n","\n","        self.dropout = ivy.Dropout(0.7)\n","        \n","        self.fc2 = ivy.Linear(1024, self.num_classes)\n","        self.softmax = ivy.Softmax()\n","        \n","    def _forward(self, x):\n","        # adap avg pool layer\n","        # display(f\"the input shape for permute_dim layer should be (1, 14, 14, 512) | and it is: {ivy.shape(x)}\")\n","        # out = ivy.permute_dims(x, (0, 3, 1, 2))\n","        \n","        display(f\"the input shape for adapAvgPool layer should be (1, 512, 14, 14) | and it is: {ivy.shape(x)}\")\n","        out = ivy.adaptive_avg_pool2d(x, [4,4])\n","        \n","        # display(f\"the input shape for permute_dim layer should be (1, 14, 14, 512) | and it is: {ivy.shape(x)}\")\n","        # out = ivy.permute_dims(out, (0, 2, 3, 1))\n","        \n","        # conv\n","        display(f\"the input shape for conv layer should be (1, 4, 4, 512) | and it is: {ivy.shape(out)}\")\n","        out = self.conv(out)\n","        \n","        # flatten\n","        display(f\"the input shape for flatten layer should be (1, 4, 4, 128) | and it is: {ivy.shape(out)}\")\n","        out = ivy.flatten(out, start_dim=1)\n","        \n","        # fc1\n","        display(f\"the input shape for fc1 layer should be (1, 2048) | and it is: {ivy.shape(out)}\")        \n","        out = self.fc1(out)\n","        \n","        display(f\"the input shape for relu layer should be (1, 1024) | and it is: {ivy.shape(out)}\")\n","        out= ivy.relu(out)\n","\n","        # dropout\n","        display(f\"the input shape for dropout layer should be (1, 1024) | and it is: {ivy.shape(out)}\")\n","        out = self.dropout(out)\n","        \n","        # fc2\n","        display(f\"the input shape for fc2 layer should be (1, 1024) | and it is: {ivy.shape(out)}\")\n","        out = self.fc2(out)\n","        display(f\"the output shape from fc2 layer should be (1, 1000) | and it is: {ivy.shape(out)}\")\n","        \n","        return out"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:37:55.988065Z","iopub.status.busy":"2023-08-06T12:37:55.987659Z","iopub.status.idle":"2023-08-06T12:38:01.234292Z","shell.execute_reply":"2023-08-06T12:38:01.233486Z","shell.execute_reply.started":"2023-08-06T12:37:55.988015Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'random_test_tensor shape is: ivy.Shape(1, 512, 14, 14)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Auxiliary block configuration is: Auxiliary(512, 1000)'"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n"]},{"data":{"text/plain":["'the input shape for adapAvgPool layer should be (1, 512, 14, 14) | and it is: ivy.Shape(1, 512, 14, 14)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for conv layer should be (1, 4, 4, 512) | and it is: ivy.Shape(1, 512, 4, 4)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for flatten layer should be (1, 4, 4, 128) | and it is: ivy.Shape(1, 128, 4, 4)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for fc1 layer should be (1, 2048) | and it is: ivy.Shape(1, 2048)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for relu layer should be (1, 1024) | and it is: ivy.Shape(1, 1024)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for dropout layer should be (1, 1024) | and it is: ivy.Shape(1, 1024)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for fc2 layer should be (1, 1024) | and it is: ivy.Shape(1, 1024)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the output shape from fc2 layer should be (1, 1000) | and it is: ivy.Shape(1, 1000)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'calc_output_shape is: ivy.Shape(1, 1000) | and true_output_shape is: (1, 1000)'"]},"metadata":{},"output_type":"display_data"}],"source":["def test_auxiliary_block():\n","    # testing with 1st ConvBlock configs in the googlenet block\n","    # ie, self.aux4A = Auxiliary(512, self.num_classes)\n","    # random_test_tensor = ivy.random_normal(shape=(1, 14, 14, 512))\n","    random_test_tensor = ivy.random_normal(shape=(1, 512, 14, 14))\n","\n","    display(f\"random_test_tensor shape is: {random_test_tensor.shape}\")\n","    \n","    auxiliary_block = Auxiliary(512, 1000)\n","    display(f\"Auxiliary block configuration is: Auxiliary(512, 1000)\")\n","    calc_output_shape = auxiliary_block(random_test_tensor).shape\n","    true_output_shape = (1, 1000)\n","    display(f\"calc_output_shape is: {calc_output_shape} | and true_output_shape is: {true_output_shape}\")\n","    \n","    assert calc_output_shape == true_output_shape;\n","\n","test_auxiliary_block()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:01.236244Z","iopub.status.busy":"2023-08-06T12:38:01.235773Z","iopub.status.idle":"2023-08-06T12:38:01.258765Z","shell.execute_reply":"2023-08-06T12:38:01.257800Z","shell.execute_reply.started":"2023-08-06T12:38:01.236214Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["class GoogLeNet(ivy.Module):\n","    def __init__(self, num_classes=1000, v: ivy.Container = None,):\n","        if v is not None:\n","            self.v = v\n","        self.num_classes = num_classes\n","        super(GoogLeNet, self).__init__(v=v)\n","\n","    def _build(self, *args, **kwargs):\n","        self.conv1 = ConvBlock(3, 64, [7,7], 2, padding=3)\n","#         self.pool1 = ivy.max_pool2d([3,3], 2, \"SAME\", ceil_mode=True)\n","\n","        self.conv2 = ConvBlock(64, 64, [1,1], 1, padding=0)\n","        self.conv3 = ConvBlock(64, 192, [3,3], 1, padding=1)\n","#         self.pool3 = ivy.max_pool2d([3,3], 2, \"SAME\", ceil_mode=True)\n","        \n","        self.inception3A = Inception(192, 64, 96, 128, 16, 32, 32)\n","        self.inception3B = Inception(256, 128, 128, 192, 32, 96, 64)\n","#         self.pool4 = ivy.max_pool2d([3,3], 2, \"SAME\", ceil_mode=True)\n","\n","        self.inception4A = Inception(480, 192, 96, 208, 16, 48, 64)\n","\n","        self.aux4A = Auxiliary(512, self.num_classes)\n","\n","        self.inception4B = Inception(512, 160, 112, 224, 24, 64, 64)\n","        self.inception4C = Inception(512, 128, 128, 256, 24, 64, 64)\n","        self.inception4D = Inception(512, 112, 144, 288, 32, 64, 64)\n","\n","        self.aux4D = Auxiliary(528, self.num_classes)\n","\n","        self.inception4E = Inception(528, 256, 160, 320, 32, 128, 128)\n","#         self.pool5 = ivy.max_pool2d([3,3], 2, \"SAME\", ceil_mode=True)\n","\n","        self.inception5A = Inception(832, 256, 160, 320, 32, 128, 128)\n","        self.inception5B = Inception(832, 384, 192, 384, 48, 128,128)\n","        self.pool6 = ivy.AdaptiveAvgPool2d([1,1])\n","\n","        self.dropout = ivy.Dropout(0.4)\n","        self.fc = ivy.Linear(1024, self.num_classes, with_bias=False)\n","\n","\n","    def _forward(self, x):\n","        display(f\"the input IMAGE shape should be (1, 224, 224, 3) | and it is: {ivy.shape(x)}\")\n","        out = self.conv1(x)\n","        \n","        # maxpool2d_1\n","        display(f\"the input shape for max_pool2d_1 should be (1, 112, 112 64) | and it is: {ivy.shape(out)}\")\n","        out = ivy.max_pool2d(out, [3,3], 2, 0, ceil_mode=True, data_format=\"NCHW\")\n","        \n","        display(f\"the input shape for conv2 should be (1, 56, 56, 64) | and it is: {ivy.shape(x)}\")\n","        out = self.conv2(out)\n","        \n","        display(f\"the input shape for conv3 shdould be (1, 56, 56, 64) | and it is: {ivy.shape(out)}\")\n","        out = self.conv3(out)\n","        \n","        # maxpool2d_2\n","        display(f\"the input shape for maxpool2d_2 shdould be (1, 56, 56, 192) | and it is: {ivy.shape(out)}\")\n","        out = ivy.max_pool2d(out, [3,3], 2, 0, ceil_mode=True, data_format=\"NCHW\")\n","        \n","        display(f\"the input shape shdould be (1, 28, 28, 192) | and it is: {ivy.shape(out)}\")\n","        out = self.inception3A(out)\n","        \n","        display(f\"the input shape shdould be (1, 28, 28, 256) | and it is: {ivy.shape(out)}\")\n","        out = self.inception3B(out)\n","        \n","        # maxpool2d_3\n","        display(f\"the input shape for maxpool2d_3 shdould be (1, 28, 28, 480) | and it is: {ivy.shape(out)}\")\n","        out = ivy.max_pool2d(out, [3,3], 2, 0, ceil_mode=True, data_format=\"NCHW\")\n","        \n","        display(f\"the input shape for inception4a shdould be (1, 14, 14, 480) | and it is: {ivy.shape(out)}\")\n","        out = self.inception4A(out)\n","\n","        display(f\"the input shape for aux4a shdould be (1, 14, 14, 512) | and it is: {ivy.shape(out)}\")\n","        aux1 = self.aux4A(out)\n","        display(f\"the output shape from aux4a shdould be (1, 1000) | and it is: {ivy.shape(out)}\")\n","        \n","        \n","        display(f\"the input shape for inception4b shdould be (1, 14, 14, 512)| and it is: {ivy.shape(out)}\")\n","        out = self.inception4B(out)\n","        \n","        display(f\"the input shape for inception4c shdould be (1, 14, 14, 512) | and it is: {ivy.shape(out)}\")\n","        out = self.inception4C(out)\n","        \n","        display(f\"the input shape for inception4 shdould be (1, 14, 14, 512) | and it is: {ivy.shape(out)}\")\n","        out = self.inception4D(out)\n","        \n","        display(f\"the input shape for aux4d shdould be (1, 14, 14, 528)  | and it is: {ivy.shape(out)}\")\n","        aux2 = self.aux4D(out)\n","        display(f\"the output shape from aux4a shdould be (1, 1000) | and it is: {ivy.shape(out)}\")\n","        \n","        \n","        display(f\"the input shape for inception4e should be (1, 14, 14, 528) | and it is: {ivy.shape(out)}\")\n","        out = self.inception4E(out)\n","        \n","        # maxpool2d_4\n","        display(f\"the input shape for maxpool2d_4 should be (1, 7, 7, 832) | and it is: {ivy.shape(out)}\")\n","        out = ivy.max_pool2d(out, [2,2], 2, 0, ceil_mode=True, data_format=\"NCHW\")\n","        \n","        display(f\"the input shape for inception5a is (1, 7, 7, 832) | and it is: {ivy.shape(out)}\")\n","        out = self.inception5A(out)\n","        \n","        display(f\"the input shape for inception5b shdould be (1, 7, 7, 1024) | and it is: {ivy.shape(out)}\")\n","        out = self.inception5B(out)\n","        \n","        display(f\"the input shape for AdpAvgPool should be (1, 1, 1, 1024) | and it is: {ivy.shape(out)}\")\n","#       out = ivy.reshape(out, (1, 1024, 7, 7))\n","        # out = ivy.permute_dims(out, (0, 3, 1, 2))\n","        out = self.pool6(out)\n","        \n","        display(f\"the input shape for flatten layer should be (1, 1, 1, 1024) | and it is: {ivy.shape(out)}\")\n","        out = ivy.flatten(out, start_dim=1)\n","        \n","        display(f\"the input shape for dropout should be (1, 1024) | and it is: {ivy.shape(out)}\")\n","        out = self.dropout(out)\n","        \n","        display(f\"the input shape for fc layer should be (1, 1024) | and it is: {ivy.shape(out)}\")\n","        out = self.fc(out)\n","        display(f\"final fc output shape should be (1, 1000) | and it is: {ivy.shape(out)}\")\n","        \n","        return out, aux1, aux2\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["'random_test_tensor shape is: ivy.Shape(1, 512, 14, 14)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'Auxiliary block configuration is: Auxiliary(512, 1000)'"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n","WARNING:root:NumPy does not support autograd, declaring a 'variable' is identical to declaring an 'array' when using numpy backend.\n"]},{"data":{"text/plain":["'the input shape for adapAvgPool layer should be (1, 512, 14, 14) | and it is: ivy.Shape(1, 512, 14, 14)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for conv layer should be (1, 4, 4, 512) | and it is: ivy.Shape(1, 512, 4, 4)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for flatten layer should be (1, 4, 4, 128) | and it is: ivy.Shape(1, 128, 4, 4)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for fc1 layer should be (1, 2048) | and it is: ivy.Shape(1, 2048)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for relu layer should be (1, 1024) | and it is: ivy.Shape(1, 1024)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for dropout layer should be (1, 1024) | and it is: ivy.Shape(1, 1024)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the input shape for fc2 layer should be (1, 1024) | and it is: ivy.Shape(1, 1024)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'the output shape from fc2 layer should be (1, 1000) | and it is: ivy.Shape(1, 1000)'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'calc_output_shape is: ivy.Shape(1, 1000) | and true_output_shape is: (1, 1000)'"]},"metadata":{},"output_type":"display_data"}],"source":["def test_googlenet_block():\n","    random_test_tensor = ivy.random_normal(shape=(1, 3, 224, 224))\n","\n","    display(f\"random_test_tensor shape is: {random_test_tensor.shape}\")\n","    \n","    auxiliary_block = Auxiliary(512, 1000)\n","    display(f\"Auxiliary block configuration is: Auxiliary(512, 1000)\")\n","    calc_output_shape = auxiliary_block(random_test_tensor).shape\n","    true_output_shape = (1, 1000)\n","    display(f\"calc_output_shape is: {calc_output_shape} | and true_output_shape is: {true_output_shape}\")\n","    \n","    assert calc_output_shape == true_output_shape;\n","\n","test_auxiliary_block()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:06.859420Z","iopub.status.busy":"2023-08-06T12:38:06.859013Z","iopub.status.idle":"2023-08-06T12:38:06.869576Z","shell.execute_reply":"2023-08-06T12:38:06.868460Z","shell.execute_reply.started":"2023-08-06T12:38:06.859391Z"},"trusted":true},"outputs":[],"source":["def _prune_keys(raw, ref, raw_keys_to_prune=[], ref_keys_to_prune=[]):\n","    pruned_ref = {}\n","    if raw_keys_to_prune:\n","        raw = raw.cont_prune_keys(raw_keys_to_prune)\n","    if ref_keys_to_prune:\n","        pruned_ref = ref.cont_at_keys(ref_keys_to_prune)\n","        ref = ref.cont_prune_keys(ref_keys_to_prune)\n","    return raw, ref, pruned_ref\n","\n","\n","def _map_weights(raw, ref, custom_mapping=None):\n","    mapping = {}\n","    for old_key, new_key in zip(\n","        raw.cont_sort_by_key().cont_to_iterator_keys(),\n","        ref.cont_sort_by_key().cont_to_iterator_keys(),\n","    ):\n","        new_mapping = new_key\n","        if custom_mapping is not None:\n","            new_mapping = custom_mapping(old_key, new_key)\n","        mapping[old_key] = new_mapping\n","    return mapping\n","\n","\n","def load_torch_weights(\n","    url,\n","    ref_model,\n","    raw_keys_to_prune=[],\n","    ref_keys_to_prune=[],\n","    custom_mapping=None,\n","    map_location=torch.device(\"cpu\"),\n","):\n","    ivy.set_backend(\"torch\")\n","    weights = torch.hub.load_state_dict_from_url(url, map_location=map_location)\n","\n","    weights_raw = ivy.to_numpy(ivy.Container(weights))\n","    weights_raw, weights_ref, pruned_ref = _prune_keys(\n","        weights_raw, ref_model.v, raw_keys_to_prune, ref_keys_to_prune\n","    )\n","    mapping = _map_weights(weights_raw, weights_ref, custom_mapping=custom_mapping)\n","\n","    ivy.previous_backend()\n","    w_clean = weights_raw.cont_restructure(mapping, keep_orig=False)\n","    if ref_keys_to_prune:\n","        w_clean = ivy.Container.cont_combine(w_clean, pruned_ref)\n","    return ivy.asarray(w_clean)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:08.963792Z","iopub.status.busy":"2023-08-06T12:38:08.963107Z","iopub.status.idle":"2023-08-06T12:38:08.970202Z","shell.execute_reply":"2023-08-06T12:38:08.969400Z","shell.execute_reply.started":"2023-08-06T12:38:08.963759Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["def _inceptionNet_torch_weights_mapping(old_key, new_key):\n","    W_KEY = [\"conv/weight\"]\n","    new_mapping = new_key\n","    if any([kc in old_key for kc in W_KEY]):\n","        new_mapping = {\"key_chain\": new_key, \"pattern\": \"b c h w -> h w c b\"}\n","    return new_mapping\n","\n","\n","def ivy_inceptionNet_v1(pretrained=True):\n","    # downlaod weights => clean theme => compare the cleaned_w_structure to model_strucutre\n","    # so this func itslef acts like a unit test for preparing the weights for the model.\n","    \"\"\"InceptionNet-V1 model\"\"\"\n","    if not pretrained:\n","        return GoogLeNet()\n","\n","    reference_model = GoogLeNet()\n","#     display(reference_model.v)\n","    url = \"https://download.pytorch.org/models/googlenet-1378be20.pth\"\n","    w_clean = load_torch_weights(\n","        url,\n","        reference_model,\n","        raw_keys_to_prune=[\"num_batches_tracked\"],\n","        custom_mapping=_inceptionNet_torch_weights_mapping,\n","        )\n","    return GoogLeNet(v=w_clean)"]},{"cell_type":"markdown","metadata":{},"source":["# torch model implementation****"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:59:07.700087Z","iopub.status.busy":"2023-08-06T12:59:07.699751Z","iopub.status.idle":"2023-08-06T12:59:07.706180Z","shell.execute_reply":"2023-08-06T12:59:07.704468Z","shell.execute_reply.started":"2023-08-06T12:59:07.700061Z"},"trusted":true},"outputs":[],"source":["import warnings\n","from collections import namedtuple\n","from functools import partial\n","from typing import Any, Callable, List, Optional, Tuple\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:08:17.683622Z","iopub.status.busy":"2023-08-06T13:08:17.683228Z","iopub.status.idle":"2023-08-06T13:08:17.702499Z","shell.execute_reply":"2023-08-06T13:08:17.700753Z","shell.execute_reply.started":"2023-08-06T13:08:17.683592Z"},"trusted":true},"outputs":[],"source":["class GoogLeNet(nn.Module):\n","    def __init__(\n","        self,\n","        num_classes: int = 1000,\n","        dropout: float = 0.2,\n","        dropout_aux: float = 0.7,\n","    ) -> None:\n","        super().__init__()\n","        conv_block = BasicConv2d\n","        inception_block = Inception\n","        inception_aux_block = InceptionAux\n","\n","        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n","        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","        self.conv2 = conv_block(64, 64, kernel_size=1)\n","        self.conv3 = conv_block(64, 192, kernel_size=3, padding=1)\n","        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","\n","        self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n","        self.inception3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n","        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n","\n","        self.inception4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n","        self.inception4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n","        self.inception4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n","        self.inception4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n","        self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n","        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n","\n","        self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n","        self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n","\n","        self.aux1 = inception_aux_block(512, num_classes, dropout=dropout_aux)\n","        self.aux2 = inception_aux_block(528, num_classes, dropout=dropout_aux)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.fc = nn.Linear(1024, num_classes)\n","\n","    def forward(self, x: Tensor) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n","        # N x 3 x 224 x 224\n","        x = self.conv1(x)\n","        # N x 64 x 112 x 112\n","        x = self.maxpool1(x)\n","        # N x 64 x 56 x 56\n","        x = self.conv2(x)\n","        # N x 64 x 56 x 56\n","        x = self.conv3(x)\n","        # N x 192 x 56 x 56\n","        x = self.maxpool2(x)\n","\n","        # N x 192 x 28 x 28\n","        x = self.inception3a(x)\n","        # N x 256 x 28 x 28\n","        x = self.inception3b(x)\n","        # N x 480 x 28 x 28\n","        x = self.maxpool3(x)\n","        # N x 480 x 14 x 14\n","        x = self.inception4a(x)\n","        # N x 512 x 14 x 14\n","        aux1 = self.aux1(x)\n","\n","        x = self.inception4b(x)\n","        # N x 512 x 14 x 14\n","        x = self.inception4c(x)\n","        # N x 512 x 14 x 14\n","        x = self.inception4d(x)\n","        # N x 528 x 14 x 14\n","        aux2 = self.aux2(x)\n","\n","        x = self.inception4e(x)\n","        # N x 832 x 14 x 14\n","        x = self.maxpool4(x)\n","        # N x 832 x 7 x 7\n","        x = self.inception5a(x)\n","        # N x 832 x 7 x 7\n","        x = self.inception5b(x)\n","        # N x 1024 x 7 x 7\n","\n","        x = self.avgpool(x)\n","        # N x 1024 x 1 x 1\n","        x = torch.flatten(x, 1)\n","        # N x 1024\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        # N x 1000 (num_classes)\n","        return x, aux2, aux1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:08:37.040651Z","iopub.status.busy":"2023-08-06T13:08:37.040261Z","iopub.status.idle":"2023-08-06T13:08:37.051252Z","shell.execute_reply":"2023-08-06T13:08:37.050164Z","shell.execute_reply.started":"2023-08-06T13:08:37.040622Z"},"trusted":true},"outputs":[],"source":["class Inception(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        ch1x1: int,\n","        ch3x3red: int,\n","        ch3x3: int,\n","        ch5x5red: int,\n","        ch5x5: int,\n","        pool_proj: int,\n","        conv_block: Optional[Callable[..., nn.Module]] = None,\n","    ) -> None:\n","        super().__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n","\n","        self.branch2 = nn.Sequential(\n","            conv_block(in_channels, ch3x3red, kernel_size=1), conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n","        )\n","\n","        self.branch3 = nn.Sequential(\n","            conv_block(in_channels, ch5x5red, kernel_size=1),\n","            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1),\n","        )\n","\n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n","            conv_block(in_channels, pool_proj, kernel_size=1),\n","        )\n","\n","    def forward(self, x: Tensor) -> List[Tensor]:\n","        branch1 = self.branch1(x)\n","        branch2 = self.branch2(x)\n","        branch3 = self.branch3(x)\n","        branch4 = self.branch4(x)\n","\n","        outputs = [branch1, branch2, branch3, branch4]\n","        return outputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:11:42.465419Z","iopub.status.busy":"2023-08-06T13:11:42.465066Z","iopub.status.idle":"2023-08-06T13:11:42.473815Z","shell.execute_reply":"2023-08-06T13:11:42.472339Z","shell.execute_reply.started":"2023-08-06T13:11:42.465391Z"},"trusted":true},"outputs":[],"source":["class InceptionAux(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        num_classes: int,\n","        conv_block: Optional[Callable[..., nn.Module]] = None,\n","        dropout: float = 0.7,\n","    ) -> None:\n","        super().__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.conv = conv_block(in_channels, 128, kernel_size=1)\n","\n","        self.fc1 = nn.Linear(2048, 1024)\n","        self.fc2 = nn.Linear(1024, num_classes)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n","        x = F.adaptive_avg_pool2d(x, (4, 4))\n","        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n","        x = self.conv(x)\n","        # N x 128 x 4 x 4\n","        x = torch.flatten(x, 1)\n","        # N x 2048\n","        x = F.relu(self.fc1(x), inplace=True)\n","        # N x 1024\n","        x = self.dropout(x)\n","        # N x 1024\n","        x = self.fc2(x)\n","        # N x 1000 (num_classes)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:18:51.683485Z","iopub.status.busy":"2023-08-06T13:18:51.683112Z","iopub.status.idle":"2023-08-06T13:18:51.690181Z","shell.execute_reply":"2023-08-06T13:18:51.689120Z","shell.execute_reply.started":"2023-08-06T13:18:51.683451Z"},"trusted":true},"outputs":[],"source":["class BasicConv2d(nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int, kernel_size, stride=1, padding=0) -> None:\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, kernel_size=kernel_size ,stride=stride, padding=padding)\n","        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        return F.relu(x, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:08:04.300875Z","iopub.status.busy":"2023-08-06T13:08:04.300215Z","iopub.status.idle":"2023-08-06T13:08:04.338266Z","shell.execute_reply":"2023-08-06T13:08:04.337092Z","shell.execute_reply.started":"2023-08-06T13:08:04.300838Z"},"trusted":true},"outputs":[],"source":["url = \"https://download.pytorch.org/models/googlenet-1378be20.pth\"\n","weights = torch.hub.load_state_dict_from_url(url, map_location='cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:18:53.500366Z","iopub.status.busy":"2023-08-06T13:18:53.499406Z","iopub.status.idle":"2023-08-06T13:18:53.666732Z","shell.execute_reply":"2023-08-06T13:18:53.665624Z","shell.execute_reply.started":"2023-08-06T13:18:53.500328Z"},"trusted":true},"outputs":[],"source":["torch_googlenet_re = GoogLeNet()\n","torch_googlenet_re.load_state_dict(weights)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# image prep"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-08-06T12:38:10.614472Z","iopub.status.busy":"2023-08-06T12:38:10.614124Z","iopub.status.idle":"2023-08-06T12:38:12.032838Z","shell.execute_reply":"2023-08-06T12:38:12.031831Z","shell.execute_reply.started":"2023-08-06T12:38:10.614445Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["import urllib\n","url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n","try: urllib.URLopener().retrieve(url, filename)\n","except: urllib.request.urlretrieve(url, filename)\n","    \n","from PIL import Image\n","dog_image = Image.open(filename)\n","display(dog_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:12.127144Z","iopub.status.busy":"2023-08-06T12:38:12.126523Z","iopub.status.idle":"2023-08-06T12:38:12.156012Z","shell.execute_reply":"2023-08-06T12:38:12.155230Z","shell.execute_reply.started":"2023-08-06T12:38:12.127111Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["# Preprocess torch image\n","from torchvision import transforms\n","from PIL import Image\n","\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","    mean=[0.485, 0.456, 0.406],\n","    std=[0.229, 0.224, 0.225]\n",")])\n","torch_img = Image.open(\"/kaggle/input/images/cat.jpg\")\n","torch_img = preprocess(dog_image)\n","torch_img = torch.unsqueeze(torch_img, 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:17.626827Z","iopub.status.busy":"2023-08-06T12:38:17.626467Z","iopub.status.idle":"2023-08-06T12:38:17.634438Z","shell.execute_reply":"2023-08-06T12:38:17.633336Z","shell.execute_reply.started":"2023-08-06T12:38:17.626797Z"},"trusted":true},"outputs":[],"source":["def load_and_preprocess_img(\n","    path,\n","    new_size,\n","    crop,\n","    mean=[0.485, 0.456, 0.406],\n","    std=[0.229, 0.224, 0.225],\n","    data_format=\"NHWC\",\n","    to_ivy=False,\n","):\n","    img = Image.open(path)\n","    compose = transforms.Compose(\n","        [\n","            transforms.Resize(new_size),\n","            transforms.CenterCrop(crop),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=mean, std=std),\n","        ]\n","    )\n","    img = compose(img)\n","    img = img.unsqueeze(0)\n","    if data_format == \"NHWC\":\n","        img = img.permute((0, 2, 3, 1))\n","    return ivy.array(img.numpy()) if to_ivy else img.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:19.130823Z","iopub.status.busy":"2023-08-06T12:38:19.130436Z","iopub.status.idle":"2023-08-06T12:38:19.169099Z","shell.execute_reply":"2023-08-06T12:38:19.168247Z","shell.execute_reply.started":"2023-08-06T12:38:19.130789Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["# Preprocess ivy image\n","img = load_and_preprocess_img(\n","        filename,\n","        256,\n","        224,\n","        to_ivy=True,\n","    )\n","print(img.shape)\n","\n","# ivy_img = torch_img.permute((0, 2, 3, 1)).detach().numpy()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# calling models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:22.188961Z","iopub.status.busy":"2023-08-06T12:38:22.188585Z","iopub.status.idle":"2023-08-06T12:38:22.467598Z","shell.execute_reply":"2023-08-06T12:38:22.466528Z","shell.execute_reply.started":"2023-08-06T12:38:22.188931Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["!echo -n gDNLm8VEO7QleBN5GdTcfMa7OHWBOWcyOiHWr2KI654= > .ivy/key.pem"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:38:22.469843Z","iopub.status.busy":"2023-08-06T12:38:22.469479Z","iopub.status.idle":"2023-08-06T12:40:21.912730Z","shell.execute_reply":"2023-08-06T12:40:21.910439Z","shell.execute_reply.started":"2023-08-06T12:38:22.469808Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["# predicting image using IVY googlenet\n","ivy.set_backend('torch')\n","ivy_googlenet = ivy_inceptionNet_v1(pretrained=True)\n","ivy_googlenet.compile(args=(img,))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:19:05.445429Z","iopub.status.busy":"2023-08-06T13:19:05.445084Z","iopub.status.idle":"2023-08-06T13:19:05.459715Z","shell.execute_reply":"2023-08-06T13:19:05.458497Z","shell.execute_reply.started":"2023-08-06T13:19:05.445402Z"},"trusted":true},"outputs":[],"source":["torch_googlenet_re.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-08-06T12:52:43.313917Z","iopub.status.busy":"2023-08-06T12:52:43.313510Z","iopub.status.idle":"2023-08-06T12:52:43.516087Z","shell.execute_reply":"2023-08-06T12:52:43.514579Z","shell.execute_reply.started":"2023-08-06T12:52:43.313886Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["# predicting torch_img using torch_googlenet\n","from torchvision.models import googlenet as torch_googlenet, GoogLeNet_Weights\n","# torch_googlenet = torch_googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1)\n","torch_googlenet = torch_googlenet(pretrained=True)\n","torch_googlenet.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T12:52:47.635530Z","iopub.status.busy":"2023-08-06T12:52:47.635178Z","iopub.status.idle":"2023-08-06T12:52:48.272774Z","shell.execute_reply":"2023-08-06T12:52:48.271841Z","shell.execute_reply.started":"2023-08-06T12:52:47.635505Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n","with open(\"imagenet_classes.txt\", \"r\") as f:\n","    categories = [s.strip() for s in f.readlines()]"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# predicting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:20:16.949071Z","iopub.status.busy":"2023-08-06T13:20:16.948627Z","iopub.status.idle":"2023-08-06T13:21:48.190253Z","shell.execute_reply":"2023-08-06T13:21:48.189100Z","shell.execute_reply.started":"2023-08-06T13:20:16.949017Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["output = ivy.softmax(ivy_googlenet(tuple(img))[0])  # pass the image to the model\n","classes = ivy.argsort(output[0], descending=True)[:3]  # get the top 3 classes\n","logits = ivy.gather(output[0], classes)  # get the logits\n","\n","print(\"Indices of the top 3 classes are:\", classes)\n","print(\"Logits of the top 3 classes are:\", logits)\n","print(\"Categories of the top 3 classes are:\", [categories[i] for i in classes.to_list()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-06T13:21:48.192228Z","iopub.status.busy":"2023-08-06T13:21:48.191874Z","iopub.status.idle":"2023-08-06T13:21:48.265750Z","shell.execute_reply":"2023-08-06T13:21:48.264748Z","shell.execute_reply.started":"2023-08-06T13:21:48.192201Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["torch_output = torch.softmax(torch_googlenet(torch_img), dim=1)\n","torch_classes = torch.argsort(torch_output[0], descending=True)[:3]\n","torch_logits = torch.take(torch_output[0], torch_classes)\n","\n","print(\"Indices of the top 3 classes are:\", torch_classes)\n","print(\"Logits of the top 3 classes are:\", torch_logits)\n","print(\"Categories of the top 3 classes are:\", [categories[i] for i in torch_classes])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-08-06T13:19:13.369242Z","iopub.status.busy":"2023-08-06T13:19:13.368819Z","iopub.status.idle":"2023-08-06T13:19:13.584630Z","shell.execute_reply":"2023-08-06T13:19:13.583330Z","shell.execute_reply.started":"2023-08-06T13:19:13.369210Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["torch_googlenet_re(torch_img)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"source":["# asserting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-08-06T08:48:35.544574Z","iopub.status.idle":"2023-08-06T08:48:35.544943Z","shell.execute_reply":"2023-08-06T08:48:35.544779Z","shell.execute_reply.started":"2023-08-06T08:48:35.544761Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["assert output.shape == tuple([1, 1000])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:33:02.556367Z","iopub.status.idle":"2023-08-05T15:33:02.556727Z","shell.execute_reply":"2023-08-05T15:33:02.556550Z","shell.execute_reply.started":"2023-08-05T15:33:02.556535Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["assert np.array_equal(torch_classes, classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:33:02.557968Z","iopub.status.idle":"2023-08-05T15:33:02.558321Z","shell.execute_reply":"2023-08-05T15:33:02.558156Z","shell.execute_reply.started":"2023-08-05T15:33:02.558141Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["assert torch.allclose(torch_logits, logits, rtol=0.5)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":4}
