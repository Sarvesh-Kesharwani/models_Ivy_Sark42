{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # %%script python -- arg1 arg2 arg3\n",
    "\n",
    "# import ivy\n",
    "# ivy.set_backend(\"torch\")\n",
    "# from googlenet import inceptionNet_v1\n",
    "# from ivy_models_tests import helpers\n",
    "# import torch\n",
    "\n",
    "# def test():\n",
    "#     model = inceptionNet_v1(pretrained=False)\n",
    "#     output = model(torch.randn(1, 3, 224, 224))\n",
    "#     print(output.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'ivy' has no attribute 'utils' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# global\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mivy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mivy_models\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m/ivy/ivy/ivy/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mivy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhandler\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mivy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m __version__\n\u001b[0;32m---> 15\u001b[0m _not_imported_backends \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ivy\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mhandler\u001b[39m.\u001b[39m_backend_dict\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[39m# Skip numpy from frameworks installed\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     _not_imported_backends\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'ivy' has no attribute 'utils' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# global\n",
    "import ivy\n",
    "import ivy_models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ivy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Building the initial Convolutional Block\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mConvBlock\u001b[39;00m(ivy\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, in_channels, out_channels, kernel_size, stride, padding):\n\u001b[1;32m      4\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_channels \u001b[39m=\u001b[39m in_channels\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ivy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building the initial Convolutional Block\n",
    "class ConvBlock(ivy.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.conv = ivy.Conv2D(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding, with_bias=False)\n",
    "        self.bn = ivy.BatchNorm2D(self.out_channels)\n",
    "        self.activation = ivy.ReLU()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Inception(ivy.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        num1x1,\n",
    "        num3x3_reduce,\n",
    "        num3x3,\n",
    "        num5x5_reduce,\n",
    "        num5x5,\n",
    "        pool_proj,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.num1x1 = num1x1\n",
    "        self.num3x3_reduce = num3x3_reduce\n",
    "        self.num3x3 = num3x3\n",
    "        self.num5x5_reduce = num5x5_reduce\n",
    "        self.num5x5 = num5x5\n",
    "        self.pool_proj = pool_proj\n",
    "        super(Inception, self).__init__()\n",
    "    \n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.block1 = ivy.Sequential(ConvBlock(self.in_channels, self.num1x1, kernel_size=[1, 1], stride=1, padding=\"SAME\")\n",
    "                                     )\n",
    "        self.block2 = ivy.Sequential(ConvBlock(self.in_channels, self.num3x3_reduce, kernel_size=[1, 1], stride=1, padding=\"SAME\"),\n",
    "                                    ConvBlock(self.num3x3_reduce, self.num3x3, kernel_size=[3, 3], stride=1, padding=\"SAME\")\n",
    "                                    )\n",
    "        self.block3 = ivy.Sequential(ConvBlock(self.in_channels, self.num5x5_reduce, kernel_size=[1, 1], stride=1, padding=\"SAME\"),\n",
    "                                    ConvBlock(self.num5x5_reduce, self.num5x5, kernel_size=[5, 5], stride=1, padding=\"SAME\")\n",
    "                                    # ConvBlock(self.num5x5_reduce, self.num5x5, kernel_size=[3, 3], stride=1, padding=\"SAME\")\n",
    "                                    )\n",
    "        self.block4 = ivy.Sequential(ivy.MaxPool2D([3,3], 1, 1),\n",
    "                                    ConvBlock(self.in_channels, self.pool_proj, kernel_size=[1, 1], stride=1, padding=\"SAME\")\n",
    "                                    )\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(x)\n",
    "        block3 = self.block3(x)\n",
    "        block4 = self.block4(x)\n",
    "\n",
    "        return ivy.concat([block1, block2, block3, block4], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Auxiliary(ivy.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        super(Auxiliary, self).__init__()\n",
    "\n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.pool = ivy.AvgPool2D([5,5], 3, \"VALID\")  # ivy.Shape(1, 4, 4, 512)\n",
    "        self.bn = ivy.BatchNorm2D(128)\n",
    "        self.conv = ivy.Conv2D(self.in_channels, 128, [1,1], 1, \"SAME\", with_bias=False)\n",
    "        self.activation = ivy.ReLU()\n",
    "        self.fc1 = ivy.Linear(2048, 1024)\n",
    "        self.dropout = ivy.Dropout(0.7)\n",
    "        self.fc2 = ivy.Linear(1024, self.num_classes)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        out = self.pool(x)\n",
    "        out = self.conv(out) # contains weights\n",
    "        out = self.activation(out)\n",
    "        out = ivy.flatten(out, start_dim=1)\n",
    "        out = self.fc1(out) # contains weights\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out) # contains weights\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GoogLeNet(ivy.Module):\n",
    "    def __init__(self, num_classes=1000, v: ivy.Container = None,):\n",
    "        if v is not None:\n",
    "            self.v = v\n",
    "        self.num_classes = num_classes\n",
    "        super(GoogLeNet, self).__init__(v=v)\n",
    "\n",
    "    def _build(self, *args, **kwargs):\n",
    "        self.conv1 = ConvBlock(3, 64, [7,7], 2, \"SAME\")\n",
    "        self.pool1 = ivy.MaxPool2D([3,3], 2, \"SAME\")\n",
    "        self.conv2 = ConvBlock(64, 64, [1,1], 1, \"VALID\")\n",
    "        self.conv3 = ConvBlock(64, 192, [3,3], 1, \"SAME\")\n",
    "        self.pool3 = ivy.MaxPool2D([3,3], 2, \"SAME\")\n",
    "        self.inception3A = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3B = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.pool4 = ivy.MaxPool2D([3,3], 2, 1)\n",
    "\n",
    "        self.inception4A = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "\n",
    "        # ivy.flatten()\n",
    "        self.aux4A = Auxiliary(512, self.num_classes)\n",
    "\n",
    "        self.inception4B = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4C = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4D = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "\n",
    "        self.aux4D = Auxiliary(528, self.num_classes)\n",
    "\n",
    "        self.inception4E = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.pool5 = ivy.MaxPool2D([3,3], 2, 1)\n",
    "\n",
    "        self.inception5A = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5B = Inception(832, 384, 192, 384, 48, 128,128)\n",
    "        self.pool6 = ivy.AvgPool2D([7,7], 1, 0) # ((1, 1))\n",
    "\n",
    "        # ivy.flatten()\n",
    "        self.dropout = ivy.Dropout(0.4)\n",
    "        self.fc = ivy.Linear(1024, self.num_classes)\n",
    "\n",
    "\n",
    "    def _forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = self.inception3A(out)\n",
    "        out = self.inception3B(out)\n",
    "        out = self.pool4(out)\n",
    "        out = self.inception4A(out)\n",
    "\n",
    "        aux1 = self.aux4A(out)\n",
    "\n",
    "        out = self.inception4B(out)\n",
    "        out = self.inception4C(out)\n",
    "        out = self.inception4D(out)\n",
    "\n",
    "        aux2 = self.aux4D(out)\n",
    "\n",
    "        out = self.inception4E(out)\n",
    "        out = self.pool5(out)\n",
    "        out = self.inception5A(out)\n",
    "        out = self.inception5B(out)\n",
    "        out = self.pool6(out)\n",
    "        out = ivy.flatten(out, start_dim=1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, aux1, aux2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GoogLeNet()\n",
    "# model.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inceptionNet_torch_weights_mapping(old_key, new_key):\n",
    "    W_KEY = [\"conv/weight\"]\n",
    "    new_mapping = new_key\n",
    "    if any([kc in old_key for kc in W_KEY]):\n",
    "        new_mapping = {\"key_chain\": new_key, \"pattern\": \"b c h w -> h w c b\"}\n",
    "    return new_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inceptionNet_v1(pretrained=True):\n",
    "    \"\"\"InceptionNet-V1 model\"\"\"\n",
    "    if not pretrained:\n",
    "        return GoogLeNet()\n",
    "\n",
    "    reference_model = GoogLeNet()\n",
    "    url = \"https://download.pytorch.org/models/googlenet-1378be20.pth\"\n",
    "    w_clean = ivy_models.helpers.load_torch_weights(\n",
    "        url,\n",
    "        reference_model,\n",
    "        raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "        custom_mapping=_inceptionNet_torch_weights_mapping,\n",
    "        )\n",
    "    display(f\"cleaned weights are: {w_clean}\")\n",
    "    display(\"calling model with weights!\")\n",
    "    return GoogLeNet(v=w_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_model = GoogLeNet()\n",
    "# url = \"https://download.pytorch.org/models/googlenet-1378be20.pth\"\n",
    "# w_clean = ivy_models.helpers.load_torch_weights(\n",
    "#     url,\n",
    "#     reference_model,\n",
    "#     raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "#     custom_mapping=_inceptionNet_torch_weights_mapping,\n",
    "#     )\n",
    "# display(w_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.models as models\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "# def inceptionNet_v1(pretrained=True):\n",
    "#     \"\"\"InceptionNet-V1 model\"\"\"\n",
    "#     if not pretrained:\n",
    "#         return models.googlenet(pretrained=False)\n",
    "\n",
    "#     reference_model = models.googlenet()\n",
    "#     url = \"https://download.pytorch.org/models/googlenet-1378be20.pth\"\n",
    "#     w_clean = torch.hub.load_state_dict_from_url(url, progress=True)\n",
    "#     # display(w_clean)\n",
    "#     # Load weights into the non-pretrained model\n",
    "#     model = models.googlenet()\n",
    "#     model.load_state_dict(w_clean)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Load GoogLeNet model\n",
    "# model = inceptionNet_v1(pretrained=True)\n",
    "# model.eval()\n",
    "\n",
    "# # Define the transformation for input image\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load and preprocess the image\n",
    "# image_path = \"/models/images/cat.jpg\"\n",
    "# image = Image.open(image_path)\n",
    "# input_tensor = preprocess(image)\n",
    "# input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "# display(input_batch.shape)\n",
    "# # Check if GPU is available, else use CPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)\n",
    "# input_batch = input_batch.to(device)\n",
    "\n",
    "# # Perform the forward pass to get predictions\n",
    "# with torch.no_grad():\n",
    "#     input_batch = input_batch.to(device)\n",
    "#     output_gt = model(input_batch)\n",
    "\n",
    "    \n",
    "# # display(model.state_dict)\n",
    "# # display(output)\n",
    "# # display(torch.max(output, 1))\n",
    "# true_indices = torch.argsort(output_gt[0], descending=True)[:3]\n",
    "# display(true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchvision.models import googlenet\n",
    "\n",
    "# input_tensor = torch.reshape(img, (1, 3, 224, 224))\n",
    "# gt_model = googlenet()\n",
    "# gt_model.eval()\n",
    "\n",
    "# # Check if GPU is available, else use CPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = gt_model.to(device)\n",
    "# input_batch = input_tensor.to(device)\n",
    "\n",
    "# # Perform the forward pass to get predictions\n",
    "# with torch.no_grad():\n",
    "#     input_batch = input_batch.to(device)\n",
    "#     output_gt = model(input_batch)\n",
    "\n",
    "# output_gt.shape\n",
    "# true_indices = torch.argsort(output_gt[0], descending=True)[:3]\n",
    "# display(true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ivy.Shape(1, 224, 224, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "\n",
    "def load_and_preprocess_img(\n",
    "    path, new_size, crop, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "):\n",
    "    img = Image.open(path)\n",
    "    compose = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(new_size),\n",
    "            transforms.CenterCrop(crop),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ]\n",
    "    )\n",
    "    img = compose(img)\n",
    "    img = img.unsqueeze(0).permute((0, 2, 3, 1))\n",
    "    return img.numpy()\n",
    "\n",
    "\n",
    "import ivy\n",
    "ivy.set_backend(\"torch\")\n",
    "\n",
    "# Load image\n",
    "this_dir = \"/models/images/cat.jpg\"\n",
    "img = ivy.asarray(load_and_preprocess_img(this_dir, 256, 224))\n",
    "# img = ivy.reshape(img, (1, 3, 224, 224))\n",
    "display(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calling model with weights!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = inceptionNet_v1(pretrained=True)\n",
    "# input_tensor = ivy.reshape(input_tensor, (1, 224, 224, 3))\n",
    "output, _, _ = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([282, 281, 285])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def inceptionNet_v1(pretrained=True):\n",
    "    \"\"\"InceptionNet-V1 model\"\"\"\n",
    "    if not pretrained:\n",
    "        return models.googlenet(pretrained=False)\n",
    "\n",
    "    reference_model = models.googlenet()\n",
    "    url = \"https://download.pytorch.org/models/googlenet-1378be20.pth\"\n",
    "    w_clean = torch.hub.load_state_dict_from_url(url, progress=True)\n",
    "    # display(w_clean)\n",
    "    # Load weights into the non-pretrained model\n",
    "    model = models.googlenet()\n",
    "    model.load_state_dict(w_clean)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load GoogLeNet model\n",
    "model = inceptionNet_v1(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation for input image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"/models/images/cat.jpg\"\n",
    "image = Image.open(image_path)\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "display(input_batch.shape)\n",
    "# Check if GPU is available, else use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "input_batch = input_batch.to(device)\n",
    "\n",
    "# Perform the forward pass to get predictions\n",
    "with torch.no_grad():\n",
    "    input_batch = input_batch.to(device)\n",
    "    output_gt = model(input_batch)\n",
    "\n",
    "    \n",
    "# display(model.state_dict)\n",
    "# display(output)\n",
    "# display(torch.max(output, 1))\n",
    "true_indices = torch.argsort(output_gt[0], descending=True)[:3]\n",
    "display(true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ivy.Shape(1, 1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(output_gt.shape)\n",
    "display(output.shape)\n",
    "# display(model.v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert output.shape == tuple([1, 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ivy.array([282, 281, 285])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([282, 281, 285])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# indices of logits in decending order from both outputs\n",
    "calc_indices = ivy.argsort(output[0], descending=True)[:3]\n",
    "# true_indices = ivy.argsort(output_gt[0], descending=True)[:3]\n",
    "display(calc_indices)\n",
    "display(true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(true_indices, calc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ivy.array([7.35792542, 7.34107494, 6.02761745])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ivy.array([6.73805046, 6.67530537, 6.46693563])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_logits = ivy.take_along_axis(output[0], calc_indices, 0)\n",
    "# true_logits = output_gt[0, true_indices[0]].tolist()\n",
    "true_logits = ivy.take_along_axis(output_gt[0], true_indices, 0)\n",
    "display(calc_logits)\n",
    "display(true_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(true_logits, calc_logits, rtol\u001b[39m=\u001b[39m\u001b[39m0.005\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(true_logits, calc_logits, rtol=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ivy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ivy\u001b[39m.\u001b[39mcompiler(inceptionNet_v1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ivy' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
